{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "header"
    ]
   },
   "source": [
    "<table width=\"100%\">\n",
    "    <tr style=\"border-bottom:solid 2pt #009EE3\">\n",
    "        <td style=\"text-align:left\" width=\"10%\">\n",
    "            <a href=\"FILENAME\" download><img src=\"../../images/icons/download.png\"></a>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\" width=\"10%\">\n",
    "            <a href=\"SOURCE\" target=\"_blank\"><img src=\"../../images/icons/program.png\" title=\"Be creative and test your solutions !\"></a>\n",
    "        </td>\n",
    "        <td></td>\n",
    "        <td style=\"text-align:left\" width=\"5%\">\n",
    "            <a href=\"../MainFiles/biosignalsnotebooks.ipynb\"><img src=\"../../images/icons/home.png\"></a>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\" width=\"5%\">\n",
    "            <a href=\"../MainFiles/contacts.ipynb\"><img src=\"../../images/icons/contacts.png\"></a>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\" width=\"5%\">\n",
    "            <a href=\"https://github.com/biosignalsnotebooks/biosignalsnotebooks\" target=\"_blank\"><img src=\"../../images/icons/github.png\"></a>\n",
    "        </td>\n",
    "        <td style=\"border-left:solid 2pt #009EE3\" width=\"15%\">\n",
    "            <img src=\"../../images/ost_logo.png\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro_info_title"
    ]
   },
   "source": [
    "<link rel=\"stylesheet\" href=\"../../styles/theme_style.css\">\n",
    "<!--link rel=\"stylesheet\" href=\"../../styles/header_style.css\"-->\n",
    "<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\">\n",
    "\n",
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td id=\"image_td\" width=\"15%\" class=\"header_image_color_7\"><div id=\"image_img\"\n",
    "        class=\"header_image_7\"></div></td>\n",
    "        <td class=\"header_text\"> Stone, Paper or Scissor Game - Train and Classify [Volume 3] </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro_info_tags"
    ]
   },
   "source": [
    "<div id=\"flex-container\">\n",
    "    <div id=\"diff_level\" class=\"flex-item\">\n",
    "        <strong>Difficulty Level:</strong>   <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star checked\"></span>\n",
    "                                <span class=\"fa fa-star\"></span>\n",
    "                                <span class=\"fa fa-star\"></span>\n",
    "    </div>\n",
    "    <div id=\"tag\" class=\"flex-item-tag\">\n",
    "        <span id=\"tag_list\">\n",
    "            <table id=\"tag_list_table\">\n",
    "                <tr>\n",
    "                    <td class=\"shield_left\">Tags</td>\n",
    "                    <td class=\"shield_right\" id=\"tags\">train_and_classify&#9729;machine-learning&#9729;features&#9729;selection</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </span>\n",
    "        <!-- [OR] Visit https://img.shields.io in order to create a tag badge-->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "source": [
    "<span class=\"color7\"><strong>Machine Learning</strong></span> is a very suggestive term to define this scientific area and the \"result\" of their algorithms. <a href=\"https://en.wikipedia.org/wiki/Machine_learning#History_and_relationships_to_other_fields\">\"Machine Learning grew out of the quest for artificial intelligence\" <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>, which inspires many people in building a totally new world with endless possibilities.\n",
    "\n",
    "In fact, only the idea of creating an intelligent system (even artificially) is both amazing and scaring, like all the ideas and discoveries that which allowed to overcome a barrier that was previously considered as immutable.\n",
    "\n",
    "In a very generic and simplistic way, <span class=\"color7\"><strong>Machine Learning</strong></span> includes the tools (algorithms) that computers can use in order to learn and acquire knowledge based on examples. The process that causes the acquisition of knowledge is called \"Training\" and it can happen in a <a href=\"https://en.wikipedia.org/wiki/Supervised_learning\">supervised <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a> or <a href=\"https://en.wikipedia.org/wiki/Unsupervised_learning\">unsupervised <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a> methodology.\n",
    "\n",
    "The main difference between the \"supervised\" and \"unsupervised\" training processes reside in the labelling of training examples, i.e., in the supervised learning algorithms the user reveals to the algorithm the class of each training example, which does not happen on the \"unsupervised\" case.\n",
    "\n",
    "After the training stage the mathematical model that supports the algorithm should have their parameters optimised and is ready to return an adequate result/class when it receives new examples to classify.\n",
    "\n",
    "Following this concepts <span class=\"color1\"><strong>biosignalsnotebooks</strong></span> contains a Notebook divided into 5 volumes covering all the procedure behind training and classification of a \"Nearest Neighbour\" classifier that will be able to distinguish between 3 possible hand gestures, using electromyographic data from two muscles and accelerometer data from one axis.\n",
    "\n",
    "Like previously referred, for a system to make a decision we should be able to provide example data from where classification can be learned and provided. Imagine creating a game that using the signals from your hand can try to guess what is the gesture you are making and play \"Paper, Stone or Scissor\" game. \n",
    "\n",
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;font-size:12pt;border-top:dotted 2px #62C3EE\">\n",
    "            <span class=\"color1\">&#9740;</span> Currently we are in possession of a file containing the feature values for all training examples, as demonstrated on a previously created <a href=\"classification_game_volume_2.ipynb\">Jupyter Notebook <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>.\n",
    "            <br>\n",
    "            However, there is a high risk that some of the extracted features are not useful for our classification system. Remember, a good feature is a parameter that has the ability to separate the different classes of our classification system, i.e, a parameter with a characteristic range of values for each available class.\n",
    "            <br>\n",
    "            In order to ensure that the training process of our classifier happens in the most efficient way, these redundant or invariant features should be removed.\n",
    "            <br>\n",
    "            The implicit logic of the last two paragraphs is called <span class=\"color7\"><strong>Feature Selection</strong></span>, which will be focused at this <span class=\"color4\"><strong>Jupyter Notebook</strong></span> !\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Starting Point (Setup)</p>\n",
    "<strong>List of Available Classes:</strong>\n",
    "<br>\n",
    "<ol start=\"0\">\n",
    "    <li><span class=\"color1\"><strong>\"No Action\"</strong></span> [When the hand is relaxed]</li>\n",
    "    <li><span class=\"color4\"><strong>\"Paper\"</strong></span> [All fingers are extended]</li>\n",
    "    <li><span class=\"color7\"><strong>\"Stone\"</strong></span> [All fingers are bent]</li>\n",
    "    <li><span class=\"color13\"><strong>\"Scissor\"</strong></span> [Forefinger and middle finger are extended and the remaining ones are bent]</li>\n",
    "</ol>\n",
    "<table align=\"center\">\n",
    "    <tr>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_paper.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_stone.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "        <td height=\"200px\">\n",
    "            <img src=\"../../images/train_and_classify/classification_game_scissor.png\" style=\"display:block;height:100%\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Paper</strong>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Stone</strong>\n",
    "        </td>\n",
    "        <td style=\"text-align:center\">\n",
    "            <strong>Scissor</strong>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<strong>Acquired Data:</strong>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Electromyography (EMG) | 2 muscles | Adductor pollicis and  Flexor digitorum superficialis</li>\n",
    "    <li>Accelerometer (ACC) | 1 axis | Sensor parallel to the thumb nail (Axis perpendicular)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Protocol/Feature Extraction</p>\n",
    "<strong>Extracted Features</strong>\n",
    "<ul>\n",
    "    <li><span style=\"color:#E84D0E\"><strong>[From] EMG signal</strong></span></li>\n",
    "    <ul>\n",
    "        <li>Standard Deviation &#9734;</li>\n",
    "        <li>Maximum sampled value &#9757;</li>\n",
    "       <li><a href=\"https://en.wikipedia.org/wiki/Zero-crossing_rate\">Zero-Crossing Rate</a> &#9740;</li>\n",
    "        <li>Standard Deviation of the absolute signal &#9735;</li>\n",
    "    </ul>\n",
    "    <li><span style=\"color:#FDC400\"><strong>[From] ACC signal</strong></span></li>\n",
    "    <ul>\n",
    "        <li>Average Value &#9737;</li>\n",
    "        <li>Standard Deviation &#9734;</li>\n",
    "        <li>Maximum sampled value &#9757;</li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/Zero-crossing_rate\">Zero-Crossing Rate</a> &#9740;</li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/Slope\">Slope of the regression curve</a> &#9741;</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<strong>Formal definition of parameters</strong>\n",
    "<br>\n",
    "&#9757; | Maximum Sample Value of a set of elements is equal to the last element of the sorted set\n",
    "\n",
    "&#9737; | $\\mu = \\frac{1}{N}\\sum_{i=1}^N (sample_i)$\n",
    "\n",
    "&#9734; | $\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(sample_i - \\mu_{signal})^2}$\n",
    "\n",
    "&#9740; | $zcr = \\frac{1}{N - 1}\\sum_{i=1}^{N-1}bin(i)$ \n",
    "\n",
    "&#9735; | $\\sigma_{abs} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(|sample_i| - \\mu_{signal_{abs}})^2}$\n",
    "\n",
    "&#9741; | $m = \\frac{\\Delta signal}{\\Delta t}$\n",
    "\n",
    "... being $N$ the number of acquired samples (that are part of the signal), $sample_i$ the value of the sample number $i$, $signal_{abs}$ the absolute signal, $\\Delta signal$ is the difference between the y coordinate of two points of the regression curve and $\\Delta t$ the difference between the x (time) coordinate of the same two points of the regression curve.\n",
    "\n",
    "... and \n",
    "\n",
    "$bin(i)$ a binary function defined as:\n",
    "\n",
    "$bin(i) = \\begin{cases} 1, & \\mbox{if } signal_i \\times signal_{i-1} \\leq 0 \\\\ 0, & \\mbox{if } signal_i \\times signal_{i-1}>0 \\end{cases}$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt;color:#62C3EE;padding-bottom:5pt\">Feature Selection</p>\n",
    "<strong>Intro</strong>\n",
    "<br>\n",
    "With <span class=\"color7\"><strong>Feature Selection</strong></span> we will start to use the resources contained inside an extremely useful <span class=\"color1\"><strong>Python</strong></span> package: <a href=\"https://scikit-learn.org/stable/index.html\">scikit-learn <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>\n",
    "\n",
    "Like described before, <span class=\"color7\"><strong>Feature Selection</strong></span> is intended to remove redundant or meaningless parameters which would increase the complexity of the classifier and not always translate into an improved performance. Without this step, the risk of overfitting to the training examples increases, making the classifier less able to categorize a new testing example.\n",
    "\n",
    "There are different approaches to feature selection such as <span class=\"color4\"><strong>filter methods</strong></span> or <span class=\"color1\"><strong>wrapper methods</strong></span>.\n",
    "\n",
    "In the first method (<span class=\"color4\"><strong>filter methods</strong></span>), a ranking will be attributed to the features, using, for example, the <strong>Pearson correlation coefficient</strong> to evaluate the impact that the feature under analysis has on the target class of the training example, or the <strong>Mutual Information parameter</strong> which defines whether two variables convey shared information. \n",
    "\n",
    "The least relevant features will be excluded and the classifier will be trained later (for a deeper explanation, please, visit the article of Girish Chandrashekar and Ferat Sahin at <a href=\"https://www.sciencedirect.com/science/article/pii/S0045790613003066\"><strong>ScienceDirect <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a>).\n",
    "\n",
    "The second methodology (<span class=\"color1\"><strong>wrapper methods</strong></span>) is characterised by the fact that the selection phase includes a classification algorithm, and features will be excluded or selected according to the quality of the trained classifier.\n",
    "\n",
    "There are also a third major methodology applicable on <span class=\"color7\"><strong>Feature Selection</strong></span>, including the so called <span class=\"color13\"><strong>embedded methods</strong></span>. Essentially this methods are a combination of <span class=\"color4\"><strong>filter</strong></span> and <span class=\"color1\"><strong>wrapper</strong></span>, being characterised by the simultaneous execution of <span class=\"color7\"><strong>Feature Selection</strong></span> and <span class=\"color13\"><strong>Training</strong></span> stages.\n",
    "\n",
    "One of the most intuitive <span class=\"color7\"><strong>Feature Selection</strong></span> methods is <span class=\"color1\"><strong>Recursive Feature Elimination</strong></span>, which will be used in the current <span class=\"color4\"><strong>Jupyter Notebook</strong></span>.\n",
    "\n",
    "Essentially the steps of this method consists in:\n",
    "<ol>\n",
    "    <li>Original set of training examples is segmented into multiple ($K$) subsets of training examples and test examples</li>\n",
    "    For each one of the $K$ subsets of training/test examples:\n",
    "    <ol>\n",
    "        <li>The training examples are used for training a \"virtual\" classifier (for example a <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\"><strong>Support Vector Machine <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a>)</li>\n",
    "        <li>The test examples are given as inputs of the trained classifier and the \"virtual\" classifier quality is estimated</li>\n",
    "    </ol>\n",
    "    <li>At this point we can estimate the average quality of the $K$ \"virtual\" classifiers and know the weight of each feature on the training stage</li>\n",
    "    <li>The feature with a smaller weight is excluded</li>\n",
    "    <li>Repetition of steps <strong>1</strong>, <strong>2</strong> and <strong>3</strong> until only one feature remains</li>\n",
    "    <li>Finally, when the \"feature elimination\" procedure ends, the set of features that provide a \"virtual\" classifier with the best average quality (step <strong>2</strong>) define the relevant features to be used during our final training stage</li>\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">0 - Import of the needed packages for a correct execution of the current <span class=\"color4\">Jupyter Notebook</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_out"
    ]
   },
   "outputs": [],
   "source": [
    "# Python package that contains functions specialized on \"Machine Learning\" tasks.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Package dedicated to the manipulation of json files.\n",
    "from json import loads, dump\n",
    "\n",
    "# Package containing a diversified set of function for statistical processing and also provide support to array operations.\n",
    "from numpy import max, array\n",
    "\n",
    "# biosignalsnotebooks own package that supports some functionalities used on the Jupyter Notebooks.\n",
    "import biosignalsnotebooks as bsnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">1 - Loading of the dictionary created on <a href=\"classification_game_volume_2.ipynb\">Volume 2 of \"Classification Game\" Jupyter Notebook <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a></p>\n",
    "This dictionary contains all the features extracted from our training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification of filename and relative path.\n",
    "relative_path = \"../../signal_samples/classification_game/features\"\n",
    "filename = \"classification_game_features.json\"\n",
    "\n",
    "# Load of data inside file storing it inside a Python dictionary.\n",
    "with open(relative_path + \"/\" + filename) as file:\n",
    "    features_dict = loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "from sty import fg, rs\n",
    "print(fg(98,195,238) + \"\\033[1mDict Keys\\033[0m\" + fg.rs + \" define the class number\")\n",
    "print(fg(232,77,14) + \"\\033[1mDict Sub-Keys\\033[0m\" + fg.rs + \" define the trial number\\n\")\n",
    "print(features_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">2 - Restructuring of \"features_dict\" to a compatible format of <a href=\"https://scikit-learn.org/stable/index.html\">scikit-learn <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a> package</p>\n",
    "features_dict must be converted to a list, containing inside it a number of sub-lists equal to the number of training examples (in our case 20). In its turn, each sub-list is formed by a number of entries equal to the number of extracted features (13 for our original formulation of the problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation of a list containing our training data and another list containing the labels of each training example.\n",
    "features_list = []\n",
    "class_training_examples = []\n",
    "\n",
    "# Access each feature list inside dictionary.\n",
    "list_classes = features_dict.keys()\n",
    "for class_i in list_classes:\n",
    "    list_trials = features_dict[class_i].keys()\n",
    "    for trial in list_trials:\n",
    "        # Storage of the class label.\n",
    "        class_training_examples += [int(class_i)]\n",
    "        features_list += [features_dict[class_i][trial]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(fg(232,77,14) + \"\\033[1m[Number of list entries;Number of sub-list entries]:\\033[0m\" + fg.rs + \" [\" + str(len(features_list)) + \"; \" + str(len(features_list[0])) + \"]\" + u'\\u2713')\n",
    "print(fg(253,196,0) + \"\\033[1mClass of each training example:\\033[0m\" + fg.rs)\n",
    "print(class_training_examples)\n",
    "print(fg(98,195,238) + \"\\033[1mFeatures List:\\033[0m\" + fg.rs)\n",
    "print(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">2.1 - Normalisation of the features values, ensuring that the training stage is not affected by scale factors</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = normalize(features_list, axis=0, norm=\"max\") # axis=0 specifies that each feature is normalised independently from the others \n",
    "                                                             # and norm=\"max\" defines that the normalization reference value will be the feature maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">3 - Selection of a classification algorithm to wrap in our <span class=\"color7\"><strong>Feature Selection</strong></span> methodology</p>\n",
    "A <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\"><strong>Support Vector Machine <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> shares some principles with <a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\"><strong>k-Nearest Neighbour Classifiers <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> (which we want to use on <a href=\"../Train_and_Classify/classification_game_volume_4.ipynb\">Jupyter Notebook [volume 4] <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>), namely the Cartesian logic, given that each example corresponds to a point with a number $N$ of coordinates equivalent to the number of features analysed (13 for our original problem), that is, each feature defines a dimension of the space.\n",
    "<br>\n",
    "Because of this \"contact point\" our \"wrapped\" classifier will be a Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a \"Support Vector Classifier\" supposing that  our classes are linearly separable.\n",
    "svc = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">4 - Configuration of the <span class=\"color4\">Recursive Feature Elimination</span> procedure given as an input our previously created \"svc\" object</p>\n",
    "Some inputs need to be given:\n",
    "<ul>\n",
    "    <li><strong>estimator</strong> - our previously created <i>\"Support Vector Classifier\"</i> object</li>\n",
    "    <li><strong>step</strong> - number of features eliminated on each iteration of the recursive algorithm</li>\n",
    "    <li><strong>cv</strong> - cross-validation method for estimating the quality of the \"virtual\" classifiers and dividing the original training set into $K$ subsets of training/test examples. The choice result in a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\"><strong>Stratified K-Fold Strategy <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></strong></a> (\"The folds are made by preserving the percentage of samples for each class\")</li>\n",
    "    <li><strong>scoring</strong> - definition of criteria for qualifying a classifier. For us the best classifier will be the one that achieve a great accuracy on classifying the test examples</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5), scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">5 - Execution of the <span class=\"color4\">Recursive Feature Elimination</span> procedure</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model.\n",
    "selector = rfecv.fit(features_list, class_training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6 - Get the optimal number of features</p>\n",
    "It will be the smallest number that provides the possibility to obtain a highest cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.1 - Get the list of average score of each virtual classifier (1 per Recursive Feature Elimination iteration)</p>\n",
    "The first element of the list refers to the average score of the trained classifiers when the set of features is 1, while the last one corresponds to the case where all features are taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of average score of the virtual classifier\n",
    "avg_scores = rfecv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.2 - Identification of the maximum score</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = max(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mMaximum Average Score:\\033[0m \" + fg.rs + str(max_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">6.3 - Identification of the smallest feature set that achieve the maximum score</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nbr_features in range(0, len(avg_scores)):\n",
    "    if avg_scores[nbr_features] == max_score:\n",
    "        optimal_nbr_features = nbr_features + 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mOptimal Number of Features:\\033[0m \" + fg.rs + str(optimal_nbr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "bsnb.plot([range(1, len(rfecv.grid_scores_) + 1)], [avg_scores], \n",
    "          y_label=[\"Cross validation score (nb of correct classifications)\"], x_label=[\"Number of features selected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">7 - Identification of the set of relevant features, taking into consideration the previously determined optimal number</p>\n",
    "It should be repeated the Recursive Feature Elimination procedure with \"RFE\" scikit-learn function, specifying the desired number of target features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=svc, step=1, n_features_to_select=optimal_nbr_features)\n",
    "\n",
    "# Fit data to the model.\n",
    "final_selector = rfe.fit(features_list, class_training_examples)\n",
    "\n",
    "# Acception/Rejection Label attributed to each feature.\n",
    "acception_labels = final_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_in"
    ]
   },
   "outputs": [],
   "source": [
    "print(fg(98,195,238) + \"\\033[1mRelevant Features (True):\\033[0m \" + fg.rs)\n",
    "print(acception_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training array has the following structure/content:\n",
    "<br>\n",
    "\\[$\\sigma_{emg\\,flexor}$, $max_{emg\\,flexor}$, $zcr_{emg\\,flexor}$, $\\sigma_{emg\\,flexor}^{abs}$, $\\sigma_{emg\\,adductor}$, $max_{emg\\,adductor}$, $zcr_{emg\\,adductor}$, $\\sigma_{emg\\,adductor}^{abs}$, $\\mu_{acc\\,z}$, $\\sigma_{acc\\,z}$, $max_{acc\\,z}$, $zcr_{acc\\,z}$, $m_{acc\\,z}$\\] \n",
    "\n",
    "So, the relevant features are:\n",
    "<ul>\n",
    "    <li>$\\sigma_{emg\\,flexor}$</li>\n",
    "    <li>$zcr_{emg\\,flexor}$</li>\n",
    "    <li>$\\sigma_{emg\\,flexor}^{abs}$</li>\n",
    "    <li>$\\sigma_{emg\\,adductor}$</li>\n",
    "    <li>$\\sigma_{emg\\,adductor}^{abs}$</li>\n",
    "    <li>$\\sigma_{acc\\,z}$</li>\n",
    "    <li>$max_{acc\\,z}$</li>\n",
    "    <li>$m_{acc\\,z}$</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">8 - Removal of meaningless features from our \"features_list\" list</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each training example and exclude meaningless entries.\n",
    "final_features_list = []\n",
    "for example_nbr in range(0, len(features_list)):\n",
    "    final_features_list += [list(array(features_list[example_nbr])[array(acception_labels)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"steps\">9 - Storage of the final list of features (after <i>Recursive Feature Elimination</i>) inside a .json file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"classification_game_features_final.json\"\n",
    "\n",
    "# Generation of .json file in our previously mentioned \"relative_path\".\n",
    "# [Generation of new file]\n",
    "with open(relative_path + \"/\" + filename, 'w') as file:\n",
    "    dump({\"features_list_final\": final_features_list, \"class_labels\": class_training_examples}, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reach the end of the \"Classification Game\" third volume. After <span class=\"color7\"><strong>Feature Selection</strong></span> all training examples are ready to be delivered to our classification algorithm in order to participate on the training process.\n",
    "\n",
    "If your are feeling your interest increasing, please jump to the next <a href=\"../Train_and_Classify/classification_game_volume_4.ipynb\">volume <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a>\n",
    "\n",
    "<strong><span class=\"color7\">We hope that you have enjoyed this guide. </span><span class=\"color2\">biosignalsnotebooks</span><span class=\"color4\"> is an environment in continuous expansion, so don't stop your journey and learn more with the remaining <a href=\"../MainFiles/biosignalsnotebooks.ipynb\">Notebooks <img src=\"../../images/icons/link.png\" width=\"10px\" height=\"10px\" style=\"display:inline\"></a></span></strong> !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "footer"
    ]
   },
   "source": [
    "<hr>\n",
    "<table width=\"100%\">\n",
    "    <tr>\n",
    "        <td style=\"border-right:solid 3px #009EE3\" width=\"20%\">\n",
    "            <img src=\"../../images/ost_logo.png\">\n",
    "        </td>\n",
    "        <td width=\"40%\" style=\"text-align:left\">\n",
    "            <a href=\"../MainFiles/aux_files/biosignalsnotebooks_presentation.pdf\" target=\"_blank\">&#9740; Project Presentation</a>\n",
    "            <br>\n",
    "            <a href=\"https://github.com/biosignalsnotebooks/biosignalsnotebooks\" target=\"_blank\">&#9740; GitHub Repository</a>\n",
    "            <br>\n",
    "            <a href=\"https://pypi.org/project/biosignalsnotebooks/\" target=\"_blank\">&#9740; How to install biosignalsnotebooks Python package ?</a>\n",
    "            <br>\n",
    "            <a href=\"../MainFiles/signal_samples.ipynb\">&#9740; Signal Library</a>\n",
    "        </td>\n",
    "        <td width=\"40%\" style=\"text-align:left\">\n",
    "            <a href=\"../MainFiles/biosignalsnotebooks.ipynb\">&#9740; Notebook Categories</a>\n",
    "            <br>\n",
    "            <a href=\"../MainFiles/by_diff.ipynb\">&#9740; Notebooks by Difficulty</a>\n",
    "            <br>\n",
    "            <a href=\"../MainFiles/by_signal_type.ipynb\">&#9740; Notebooks by Signal Type</a>\n",
    "            <br>\n",
    "            <a href=\"../MainFiles/by_tag.ipynb\">&#9740; Notebooks by Tag</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_mark",
     "aux"
    ]
   },
   "source": [
    "<span class=\"color6\">**Auxiliary Code Segment (should not be replicated by\n",
    "the user)**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_both"
    ]
   },
   "outputs": [],
   "source": [
    "from biosignalsnotebooks.__notebook_support__ import css_style_apply\n",
    "css_style_apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_both"
    ]
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'],\n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
